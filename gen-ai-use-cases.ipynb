{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "160b0034-ccf0-47a4-a916-4178bbdbaf6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04dfc733-e435-4f49-b622-47204c69f2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from inspect import cleandoc\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, GenerationConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84483221-c471-4022-a97a-5fb1898be9d6",
   "metadata": {},
   "source": [
    "Initialize Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f88d08-0578-4930-8786-c410f5b968ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT[0]\n",
    "REGION = \"us-west1\"\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4887dfd-5fbf-4da0-8325-f47b641c9d70",
   "metadata": {},
   "source": [
    "Load a generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3199fcf-a8f6-4f26-924d-59385c919fa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2c73a-be23-4a99-bb66-e5523fdbd245",
   "metadata": {},
   "source": [
    "Ideation<br>\n",
    "means using the model to help you brainstorm new content: article titles, sections to include in a document, interview questions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5628ea4-9e8c-4bda-aa5a-354d1caaf011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "creative_gen_config = GenerationConfig(temperature=1, top_p=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d964f6-dd1a-4a50-9b4c-f69325b6d29f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Strategies for Overcoming Writer's Block\n",
      "\n",
      "Writer's block is a common challenge faced by writers of all levels. It can be frustrating and discouraging, but there are a number of strategies you can use to overcome it. Here are a few:\n",
      "\n",
      "**1. Change your environment:** Sometimes a change of scenery can do wonders for creativity. Try writing in a different location, like a coffee shop, library, or park.\n",
      "**2. Take a break:** If you've been staring at your screen for hours with no progress, it's time to step away. Take a walk, do some stretches, or listen to music. When you come back to your work, you'll feel refreshed and ready to start again.\n",
      "**3. Freewrite:** This is a great way to get your thoughts flowing and to warm up your writing muscles. Just write whatever comes to mind, without worrying about grammar, punctuation, or making sense.\n",
      "**4. Do some brainstorming:** If you're not sure where to start, try brainstorming some ideas. This could involve writing down a list of keywords, mind mapping, or free associating.\n",
      "**5. Talk to someone:** Talking about your work with someone else can be helpful in getting unstuck. Try talking to a friend, family member, therapist, or writing group.\n",
      "**6. Break your task down into smaller chunks:** If you're feeling overwhelmed by a large project, try breaking it down into smaller, more manageable chunks. This will make it seem less daunting and help you get started.\n",
      "**7. Set a timer:** Sometimes the best way to get started is to just set a timer for a certain amount of time and write without stopping. Even if you don't produce anything perfect, you'll at least get some words on the page.\n",
      "**8. Reward yourself:** When you finish a writing session, reward yourself with something you enjoy. This will help you stay motivated and keep working on your project.\n",
      "**9. Don't give up:** Writer's block is a temporary setback. Don't give up on your writing. Keep trying different strategies until you find something that works for you.\n",
      "\n",
      "Here are some additional resources that you may find helpful:\n",
      "\n",
      "* **The Write Practice:** https://thewritepractice.com/\n",
      "* **Writer's Digest:** https://www.writersdigest.com/\n",
      "* **The Creative Penn:** https://www.thecreativepenn.com/\n",
      "\n",
      "I hope this information is helpful. Good luck with your writing!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are some strategies for overcoming writer's block?\"\n",
    "\n",
    "response = model.generate_content(prompt,\n",
    "                                  generation_config=creative_gen_config) \n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfc61a5-0e4c-4546-ae63-10b9a48d1e19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Prompt Engineer Interview Questions:\n",
      "\n",
      "**Technical Skills:**\n",
      "\n",
      "1. **Explain the different prompt engineering techniques and when you would use each one.**\n",
      "2. **Describe your process for creating prompts for different NLP tasks, such as text generation, classification, or summarization.**\n",
      "3. **How do you evaluate the quality of a prompt? What metrics do you use?**\n",
      "4. **Have you worked with any large language models (LLMs) before? If so, which ones and how did you use them in your prompt engineering work?**\n",
      "5. **Explain how you would go about identifying and mitigating potential biases in your prompts.**\n",
      "\n",
      "**Problem-Solving & Creativity:**\n",
      "\n",
      "6. **Describe a time when you had to overcome a technical challenge related to prompt engineering. How did you approach the problem and what was the outcome?**\n",
      "7. **Imagine you are tasked with creating a prompt for a new NLP task that has not been explored before. How would you go about brainstorming and developing a creative prompt for this task?**\n",
      "8. **How do you stay up-to-date with the latest research and advancements in the field of prompt engineering?**\n",
      "\n",
      "**Communication & Teamwork:**\n",
      "\n",
      "9. **Explain how you would collaborate with other engineers and researchers on a project involving prompt engineering.**\n",
      "10. **How do you communicate the technical aspects of your work to non-technical stakeholders?**\n",
      "\n",
      "**Bonus Question:**\n",
      "\n",
      "* What are your thoughts on the future of prompt engineering and how do you see the field evolving in the next few years?\n",
      "\n",
      "**Note:** These are just a few examples, and the specific questions you ask will depend on the specific role and your company's needs. \n",
      "\n",
      "**Additionally, you may want to consider asking some behavioral questions to assess the candidate's soft skills and cultural fit.** \n",
      "\n",
      "I hope this helps!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Provide ten interview questions for the role of prompt engineer.\"\n",
    "\n",
    "response = model.generate_content(prompt,\n",
    "                                  generation_config=creative_gen_config) \n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611a263c-498d-48e2-bb0d-858c198c82c8",
   "metadata": {},
   "source": [
    "Text Classification<br>\n",
    "Classification can have many possible applications, including:<br>\n",
    "\n",
    "Sentiment analysis<br>\n",
    "Topic classification<br>\n",
    "Spam detection<br>\n",
    "Intent recognition<br>\n",
    "Language identification<br>\n",
    "Toxicity detection<br>\n",
    "Emotion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe3dd756-e894-462d-a224-9b84fa35a15f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictable_gen_config = GenerationConfig(temperature=0.1, top_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb29fab-e36a-40cf-829e-e32209b7f055",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Making a reservation\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Given a user's input, classify their intent, such as \"finding information\", \"making a reservation\", or \"placing an order\". \\n\n",
    "user input: Hi, can you please book a table for two at Juan for May 1?\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt, generation_config=predictable_gen_config\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2da25dbd-fb70-4eb9-abd9-43ee5636eda2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entertainment \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What is the topic for a given news headline? \\n\n",
    "- business \\n\n",
    "- entertainment \\n\n",
    "- health \\n\n",
    "- sports \\n\n",
    "- technology \\n\\n\n",
    "\n",
    "Text: Pixel 7 Pro Expert Hands On Review. \\n\n",
    "The answer is: technology \\n\n",
    "\n",
    "Text: Quit smoking? \\n\n",
    "The answer is: health \\n\n",
    "\n",
    "Text: Birdies or bogeys? Top 5 tips to hit under par \\n\n",
    "The answer is: sports \\n\n",
    "\n",
    "Text: Relief from local minimum-wage hike looking more remote \\n\n",
    "The answer is: business \\n\n",
    "\n",
    "Text: You won't guess who just arrived in Bari, Italy for the movie premiere. \\n\n",
    "The answer is:\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt, generation_config=predictable_gen_config\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce556b1-daed-4ef7-8552-21f852f3ba64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment_groundtruth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love this product. it does have everything i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all i can say is that you will be happy after ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its way too expensive and not worth the price</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am feeling okay. its neither good nor too bad.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment_groundtruth\n",
       "0  i love this product. it does have everything i...              positive\n",
       "1  all i can say is that you will be happy after ...              positive\n",
       "2      its way too expensive and not worth the price              negative\n",
       "3   i am feeling okay. its neither good nor too bad.               neutral"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "review_data_df = pd.DataFrame(\n",
    "    {\n",
    "        \"review\": [\n",
    "            \"i love this product. it does have everything i am looking for!\",\n",
    "            \"all i can say is that you will be happy after buying this product\",\n",
    "            \"its way too expensive and not worth the price\",\n",
    "            \"i am feeling okay. its neither good nor too bad.\",\n",
    "        ],\n",
    "        \"sentiment_groundtruth\": [\"positive\", \"positive\", \"negative\", \"neutral\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "review_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdec3e19-7fd2-4286-bfe7-3a7f03ae8fff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment_groundtruth</th>\n",
       "      <th>sentiment_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love this product. it does have everything i...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>all i can say is that you will be happy after ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its way too expensive and not worth the price</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am feeling okay. its neither good nor too bad.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment_groundtruth  \\\n",
       "0  i love this product. it does have everything i...              positive   \n",
       "1  all i can say is that you will be happy after ...              positive   \n",
       "2      its way too expensive and not worth the price              negative   \n",
       "3   i am feeling okay. its neither good nor too bad.               neutral   \n",
       "\n",
       "  sentiment_prediction  \n",
       "0             positive  \n",
       "1             positive  \n",
       "2             negative  \n",
       "3              neutral  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentiment(row):\n",
    "    prompt = f\"\"\"Classify the sentiment of the following review as \"positive\", \"neutral\" or \"negative\". Return only the classification.\n",
    "                review: {row}\n",
    "              \"\"\"\n",
    "    response = model.generate_content(\n",
    "        contents=prompt, generation_config=predictable_gen_config\n",
    "    ).text\n",
    "    return response\n",
    "\n",
    "\n",
    "review_data_df[\"sentiment_prediction\"] = review_data_df[\"review\"].apply(get_sentiment)\n",
    "review_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0ea6418-6739-468e-80d2-753679a2f5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "              precision    recall  f1-score   support\n",
       "\n",
       "    negative       1.00      1.00      1.00         1\n",
       "     neutral       1.00      1.00      1.00         1\n",
       "    positive       1.00      1.00      1.00         2\n",
       "\n",
       "    accuracy                           1.00         4\n",
       "   macro avg       1.00      1.00      1.00         4\n",
       "weighted avg       1.00      1.00      1.00         4\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(\n",
    "    review_data_df[\"sentiment_groundtruth\"], review_data_df[\"sentiment_prediction\"]\n",
    ")\n",
    "Markdown(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac9150-d120-46a8-ab2f-d2f5e9173f13",
   "metadata": {},
   "source": [
    "Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "866360b7-1d18-4517-b22c-3c0e13693599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictable_gen_config = GenerationConfig(temperature=0.1, top_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d369041b-1932-4399-8ad1-0b15c8ae329b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Summary:\n",
      "\n",
      "Quantum computers are sensitive to errors, which can be mitigated by using quantum error correction. This technique encodes information across multiple qubits, creating a \"logical qubit\" with lower error rates. By using logical qubits, quantum computers can achieve the accuracy needed for useful calculations. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Provide a very short summary, no more than three sentences, for the following article:\n",
    "\n",
    "Our quantum computers work by manipulating qubits in an orchestrated fashion that we call quantum algorithms.\n",
    "The challenge is that qubits are so sensitive that even stray light can cause calculation errors — and the problem worsens as quantum computers grow.\n",
    "This has significant consequences, since the best quantum algorithms that we know for running useful applications require the error rates of our qubits to be far lower than we have today.\n",
    "To bridge this gap, we will need quantum error correction.\n",
    "Quantum error correction protects information by encoding it across multiple physical qubits to form a \"logical qubit,\" and is believed to be the only way to produce a large-scale quantum computer with error rates low enough for useful calculations.\n",
    "Instead of computing on the individual qubits themselves, we will then compute on logical qubits. By encoding larger numbers of physical qubits on our quantum processor into one logical qubit, we hope to reduce the error rates to enable useful quantum algorithms.\n",
    "\n",
    "Summary:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt, generation_config=predictable_gen_config\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0111b2d3-dc90-4802-ab21-9554aa3ad7e2",
   "metadata": {},
   "source": [
    "prefer your summary to be delivered as bullet points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4afe3be-1f4b-49ce-bb7e-1beb4bda013f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Summary in four bullet points:\n",
       "\n",
       "* **Quantum computers use qubits, which are sensitive to errors.** Even small disturbances like stray light can cause calculation errors.\n",
       "* **Current error rates are too high for useful applications.** The best quantum algorithms require much lower error rates than we have today.\n",
       "* **Quantum error correction is the solution.** It encodes information across multiple qubits to create a \"logical qubit\" with lower error rates.\n",
       "* **Logical qubits will enable useful quantum algorithms.** By encoding physical qubits into logical qubits, we can achieve the low error rates needed for practical applications. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Provide a very short summary in four bullet points for the following article:\n",
    "\n",
    "Our quantum computers work by manipulating qubits in an orchestrated fashion that we call quantum algorithms.\n",
    "The challenge is that qubits are so sensitive that even stray light can cause calculation errors — and the problem worsens as quantum computers grow.\n",
    "This has significant consequences, since the best quantum algorithms that we know for running useful applications require the error rates of our qubits to be far lower than we have today.\n",
    "To bridge this gap, we will need quantum error correction.\n",
    "Quantum error correction protects information by encoding it across multiple physical qubits to form a \"logical qubit,\" and is believed to be the only way to produce a large-scale quantum computer with error rates low enough for useful calculations.\n",
    "Instead of computing on the individual qubits themselves, we will then compute on logical qubits. By encoding larger numbers of physical qubits on our quantum processor into one logical qubit, we hope to reduce the error rates to enable useful quantum algorithms.\n",
    "\n",
    "Bullet points:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    contents=prompt, generation_config=predictable_gen_config\n",
    ")\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48078b95-5317-4d22-afc1-4e5c3594850a",
   "metadata": {},
   "source": [
    "Summarization can also be done on other forms of documents, like an email thread or the transcript of a conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70ca8704-2144-43f1-8735-7f3a59ecd0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Summary of Conversation:\n",
       "\n",
       "* **Customer:** Larry received the wrong item.\n",
       "* **Desired Resolution:** Return the item and receive a refund.\n",
       "* **Resolution:** Support Agent processed the refund.\n",
       "* **Refund Timeline:** Customer will receive the refund within 14 days.\n",
       "\n",
       "## To-Dos for Support Agent:\n",
       "\n",
       "* **None.** The Support Agent has already completed the necessary actions. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Please generate a summary of the following conversation and at the end summarize the to-do's for the support Agent:\n",
    "\n",
    "Customer: Hi, I'm Larry, and I received the wrong item.\n",
    "\n",
    "Support Agent: Hi, Larry. How would you like to see this resolved?\n",
    "\n",
    "Customer: That's alright. I want to return the item and get a refund, please.\n",
    "\n",
    "Support Agent: Of course. I can process the refund for you now. Can I have your order number, please?\n",
    "\n",
    "Customer: It's [ORDER NUMBER].\n",
    "\n",
    "Support Agent: Thank you. I've processed the refund, and you will receive your money back within 14 days.\n",
    "\n",
    "Customer: Thank you very much.\n",
    "\n",
    "Support Agent: You're welcome, Larry. Have a good day!\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    contents=prompt, generation_config=predictable_gen_config\n",
    ")\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee3e66-a08f-4341-a07d-4fb17b4ca6d3",
   "metadata": {},
   "source": [
    "Text Extraction<br>\n",
    "By unstructured text, we mean text that lacks a computer-readable structure like CSV, JSON, or YAML,<br>\n",
    "even if a human can identify some structure (like in the ingredient list of a recipe).<br>\n",
    "<br>\n",
    "Some specific types of extraction include:<br>\n",
    " - Named entity recognition (NER): Extract named entities from text, including people, places, organizations, and dates.<br>\n",
    " - Relation extraction: Extract the relationships between entities in text, such as family relationships between people.<br>\n",
    " - Event extraction: Extract events from text, such as project milestones and product launches.<br>\n",
    " - Question answering: Extract information from text to answer a question.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b32146f1-5f1c-453b-8fe2-02afac331a79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
      "    \"cheese_selection\": \"Swiss\"\n",
      "  },\n",
      "  {\n",
      "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
      "    \"cheese_selection\": \"Swiss\"\n",
      "  },\n",
      "  {\n",
      "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
      "    \"cheese_selection\": \"Muenster\"\n",
      "  },\n",
      "  {\n",
      "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
      "    \"cheese_selection\": \"Muenster\"\n",
      "  },\n",
      "  {\n",
      "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
      "    \"cheese_selection\": \"Muenster\"\n",
      "  },\n",
      "  {\n",
      "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
      "    \"cheese_selection\": \"Cheddar\"\n",
      "  },\n",
      "  {\n",
      "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
      "    \"cheese_selection\": \"Cheddar\"\n",
      "  },\n",
      "  {\n",
      "    \"item_name\": \"Grilled Cheese Sandwich\",\n",
      "    \"cheese_selection\": \"Cheddar\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "order = \"We need eight grilled cheese sandwiches. Two with swiss cheese, three with muenster, three with cheddar.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "    Break the customer's order into individual items with keys for the following fields:\n",
    "    - item_name\n",
    "    - cheese_selection\n",
    "\n",
    "    Order:\n",
    "    {order_field}\n",
    "\"\"\".format(order_field=order)\n",
    "\n",
    "response = model.generate_content(\n",
    "    contents=prompt, generation_config=predictable_gen_config\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3a0fe-1262-412f-9eda-a2b8757b5be1",
   "metadata": {},
   "source": [
    "Question answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24447824-e7bf-464d-9bab-97eac129b5ed",
   "metadata": {},
   "source": [
    "Answering an open domain question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb9c4059-fa5f-493f-9df1-19573653c9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Who was President of the United States in 1955?\n",
      "\n",
      "In 1955, **Dwight D. Eisenhower** was President of the United States. He was inaugurated on January 20, 1953, and served two terms, ending on January 20, 1961. \n",
      "\n",
      "## Which party did he belong to?\n",
      "\n",
      "Dwight D. Eisenhower belonged to the **Republican Party**. He was the first Republican president after 20 years of Democratic presidents. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Q: Who was President of the United States in 1955?\n",
    "              Which party did he belong to?\n",
    "            A:\n",
    "        \"\"\"\n",
    "response = model.generate_content(\n",
    "    contents=prompt, generation_config=predictable_gen_config\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe76db-9df6-4282-bad5-8be598933a79",
   "metadata": {
    "tags": []
   },
   "source": [
    "Answering an closed domain question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "232c956f-3971-415e-ba2b-a9fa2fd92293",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prompt]\n",
      "Answer the question given in the contex below:\n",
      "Context: \n",
      "Storage and content policy \n",
      "\n",
      "How durable is my data in Cloud Storage? \n",
      "\n",
      "Cloud Storage is designed for 99.999999999% (11 9's) annual durability, which is appropriate for even primary storage and\n",
      "business-critical applications. This high durability level is achieved through erasure coding that stores data pieces redundantly\n",
      "across multiple devices located in multiple availability zones.\n",
      "Objects written to Cloud Storage must be redundantly stored in at least two different availability zones before the\n",
      "write is acknowledged as successful. Checksums are stored and regularly revalidated to proactively verify that the data\n",
      "integrity of all data at rest as well as to detect corruption of data in transit. If required, corrections are automatically\n",
      "made using redundant data. Customers can optionally enable object versioning to add protection against accidental deletion.\n",
      "?\n",
      "\n",
      "Question: How is high availability achieved? \n",
      "\n",
      "Answer:\n",
      "\n",
      "[Response]\n",
      "## High Availability in Cloud Storage\n",
      "\n",
      "Cloud Storage achieves high availability through a combination of redundancy and proactive measures:\n",
      "\n",
      "**Redundancy:**\n",
      "\n",
      "* **Erasure coding:** Data is split into pieces and stored redundantly across multiple devices in different availability zones. This ensures that even if some devices fail, the data remains accessible.\n",
      "* **Object versioning:** This optional feature allows you to keep multiple versions of your objects, protecting against accidental deletion or modification.\n",
      "\n",
      "**Proactive measures:**\n",
      "\n",
      "* **Checksums:** These are used to verify the integrity of data at rest and in transit. Any corruption is automatically detected and corrected using the redundant data.\n",
      "* **Regular revalidation:** Checksums are regularly revalidated to ensure data integrity is maintained over time.\n",
      "\n",
      "**Additional factors:**\n",
      "\n",
      "* **Multiple availability zones:** Data is stored across multiple geographically dispersed availability zones, minimizing the impact of localized outages.\n",
      "* **Automatic failover:** In case of a device failure, the system automatically reroutes requests to healthy devices, ensuring continuous availability.\n",
      "\n",
      "These measures work together to ensure that your data is highly available and accessible even in the event of hardware failures, network disruptions, or other unexpected events. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "Storage and content policy \\n\n",
    "How durable is my data in Cloud Storage? \\n\n",
    "Cloud Storage is designed for 99.999999999% (11 9's) annual durability, which is appropriate for even primary storage and\n",
    "business-critical applications. This high durability level is achieved through erasure coding that stores data pieces redundantly\n",
    "across multiple devices located in multiple availability zones.\n",
    "Objects written to Cloud Storage must be redundantly stored in at least two different availability zones before the\n",
    "write is acknowledged as successful. Checksums are stored and regularly revalidated to proactively verify that the data\n",
    "integrity of all data at rest as well as to detect corruption of data in transit. If required, corrections are automatically\n",
    "made using redundant data. Customers can optionally enable object versioning to add protection against accidental deletion.\n",
    "\"\"\"\n",
    "\n",
    "question = \"How is high availability achieved?\"\n",
    "\n",
    "prompt = f\"\"\"Answer the question given in the contex below:\n",
    "Context: {context}?\\n\n",
    "Question: {question} \\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(\"[Prompt]\")\n",
    "print(prompt)\n",
    "\n",
    "print(\"[Response]\")\n",
    "response = model.generate_content(contents=prompt, generation_config=predictable_gen_config)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
